{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import import_ipynb\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myJAAD(torch.utils.data.Dataset):\n",
    "    def __init__(self, args):\n",
    "        \n",
    "        if(args.from_file):\n",
    "            sequence_centric = pd.read_csv(args.file)\n",
    "            df = sequence_centric.copy()\n",
    "            if not args.citywalks:\n",
    "                df = df.drop(columns=['ID'])\n",
    "            for v in list(df.columns.values):\n",
    "                print(v)\n",
    "                df.loc[:,v] = df.loc[:, v].apply(lambda x: literal_eval(x))\n",
    "            sequence_centric[df.columns] = df[df.columns]\n",
    "            \n",
    "        else:\n",
    "            #read data\n",
    "            df = pd.DataFrame()\n",
    "            new_index=0\n",
    "            for file in glob.glob(os.path.join(args.jaad_dataset,args.dtype,\"*\")):\n",
    "                temp = pd.read_csv(file)\n",
    "                if not temp.empty:\n",
    "                    #drop unnecessary columns\n",
    "                    temp = temp.drop(columns=['type', 'occlusion', 'nod', 'slow_down', 'speed_up', 'WALKING', 'walking',\n",
    "                   'standing', 'looking', 'handwave', 'clear_path', 'CLEAR_PATH','STANDING', \n",
    "                   'standing_pred', 'looking_pred', 'walking_pred','keypoints', 'crossing_pred'])\n",
    "                    \n",
    "                    temp['file'] = [file for t in range(temp.shape[0])]\n",
    "\n",
    "                    #assign unique ID to each \n",
    "                    for index in temp.ID.unique():\n",
    "                        new_index += 1\n",
    "                        temp.ID = temp.ID.replace(index, new_index)\n",
    "\n",
    "                    #sort rows by ID and frames\n",
    "                    temp = temp.sort_values(['ID', 'frame'], axis=0)\n",
    "\n",
    "                    df = df.append(temp, ignore_index=True)\n",
    "            print('reading files complete')\n",
    "            \n",
    "            #create sequence column\n",
    "            df.insert(0, 'sequence', df.ID)\n",
    "            \n",
    "            df = df.apply(lambda row: utils.compute_center(row), axis=1)\n",
    "\n",
    "            #reset index\n",
    "            df = df.reset_index(drop = True)\n",
    "            \n",
    "            #drop rest if not dividable by sequence len\n",
    "            length = 0\n",
    "            for index in df.ID.unique():\n",
    "                rest = len(df[df['sequence'] == index]) % args.seq_len\n",
    "                index_1 = length + df[df['sequence'] == index].shape[0]-rest\n",
    "                index_2 = length + df[df['sequence'] == index].shape[0]-1\n",
    "                length = index_2 + 1\n",
    "                if rest != 0:\n",
    "                    df = df.drop(df.loc[index_1:index_2].index)\n",
    "            print('frame drop complete')\n",
    "            \n",
    "            #reset IDs\n",
    "            new_index=0\n",
    "            for index in df.ID.unique():\n",
    "                df.loc[df['ID'] == index, 'ID'] = new_index\n",
    "                new_index += 1\n",
    "            print('reindexing complete')\n",
    "            \n",
    "            #reset index\n",
    "            df = df.reset_index(drop=True)\n",
    "            \n",
    "            self.df = df\n",
    "            \n",
    "            #create sequences and assign sequence values\n",
    "            sequences = np.linspace(0, (df.shape[0]/args.seq_len)-1, int(df.shape[0]/args.seq_len), dtype=np.int64)\n",
    "            sequences = np.repeat(sequences, args.seq_len)\n",
    "            df.sequence = sequences\n",
    "            print('sequence assignment complete')\n",
    "            \n",
    "            df['bounding_box'] = list(zip(df.x, df.y, df.w, df.h))\n",
    "            df['im_size'] = list(zip(df.im_w, df.im_h))\n",
    "            df.bounding_box = df.bounding_box.apply(list)\n",
    "            df.im_size = df.im_size.apply(list)\n",
    "            df = df.drop(columns=['x', 'y', 'w', 'h'])\n",
    "            df = df.drop(columns=['im_w', 'im_h'])\n",
    "            \n",
    "            #create sequence centric datafrae\n",
    "            sequence_centric = pd.DataFrame()\n",
    "            sequence_centric = df.groupby('sequence').agg(lambda x: x.tolist())\n",
    "            sequence_centric.ID = sequence_centric.ID.apply(lambda x: x[0])\n",
    "            print('sequence centric complete')\n",
    "            \n",
    "            sequence_centric['future_bounding_box'] = sequence_centric['bounding_box']\n",
    "            tmp = sequence_centric.copy()\n",
    "            for ind in tmp.ID.unique():\n",
    "                tmp = tmp.drop(tmp[tmp['ID'] == ind].index[0])\n",
    "                sequence_centric = sequence_centric.drop(sequence_centric[sequence_centric['ID'] == ind].index[-1])\n",
    "    \n",
    "            tmp = tmp.reset_index(drop=True)\n",
    "            sequence_centric = sequence_centric.reset_index(drop=True)\n",
    "\n",
    "            sequence_centric['future_bounding_box'] = tmp['bounding_box']\n",
    "            \n",
    "        if args.sample:\n",
    "            if args.trainOrVal == 'train':\n",
    "                self.data = sequence_centric.loc[:args.n_train_sequences].copy().reset_index(drop=True)\n",
    "            elif args.trainOrVal == 'val':\n",
    "                self.data = sequence_centric.loc[args.n_train_sequences:args.n_train_sequences+args.n_val_sequences].copy().reset_index(drop=True)\n",
    "    \n",
    "        else:\n",
    "            self.data = sequence_centric.copy().reset_index(drop=True)\n",
    "            \n",
    "        self.args = args\n",
    "        self.dtype = args.dtype\n",
    "        print(self.dtype, \" loaded\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        seq = self.data.iloc[index]\n",
    "\n",
    "        observed = torch.tensor(seq.bounding_box)\n",
    "\n",
    "        future = torch.tensor(seq.future_bounding_box)\n",
    "        \n",
    "        obs = torch.cat((observed[0].unsqueeze(0), observed[2].unsqueeze(0), observed[4].unsqueeze(0), \n",
    "                         observed[6].unsqueeze(0), observed[8].unsqueeze(0), observed[10].unsqueeze(0), \n",
    "                         observed[12].unsqueeze(0), observed[14].unsqueeze(0), observed[16].unsqueeze(0)), dim=0)\n",
    "        true = torch.cat((future[0].unsqueeze(0), future[2].unsqueeze(0), future[4].unsqueeze(0), \n",
    "                          future[6].unsqueeze(0), future[8].unsqueeze(0), future[10].unsqueeze(0), \n",
    "                          future[12].unsqueeze(0), future[14].unsqueeze(0), future[16].unsqueeze(0)), dim=0)\n",
    "        \n",
    "        obs_speed = obs[1:9] - obs[:8]\n",
    "        true_speed = true[1:9] - true[:8]\n",
    "        \n",
    "        return obs_speed, true_speed, obs, true\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(args):\n",
    "    train_set = myJAAD(args)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=args.batch_size, shuffle=args.loader_shuffle,\n",
    "        pin_memory=args.pin_memory, num_workers=args.loader_workers, drop_last=True)\n",
    "    \n",
    "    args.trainOrVal = 'val'\n",
    "    \n",
    "    val_set = myJAAD(args)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set, batch_size=args.batch_size, shuffle=args.loader_shuffle,\n",
    "        pin_memory=args.pin_memory, num_workers=args.loader_workers, drop_last=True)\n",
    "    \n",
    "    args.file = args.val_file\n",
    "    args.dtype = 'val'\n",
    "    args.trainOrVal = 'test'\n",
    "    args.sample = False\n",
    "    \n",
    "    test_set = myJAAD(args)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=args.batch_size, shuffle=args.loader_shuffle,\n",
    "        pin_memory=args.pin_memory, num_workers=args.loader_workers, drop_last=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
