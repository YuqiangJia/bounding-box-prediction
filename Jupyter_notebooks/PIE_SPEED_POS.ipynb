{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from networks.ipynb\n",
      "importing Jupyter notebook from DataLoader_PIE.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import import_ipynb\n",
    "import networks\n",
    "import DataLoader_PIE\n",
    "import utils\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        self.base_out_features = 2048\n",
    "        self.t_obs = 8\n",
    "        self.batch_size = 20\n",
    "        self.scene_shape = [3, 144, 256]\n",
    "        self.base_shape = [2048, 9, 16]\n",
    "        self.hidden_size = 128\n",
    "        self.embedding_size = 64\n",
    "        self.input_size = 2\n",
    "        self.output_size = 2\n",
    "        self.sample = True\n",
    "        self.n_train_sequences = 15000\n",
    "        self.n_val_sequences = 10\n",
    "        self.trainOrVal = 'train'\n",
    "        \n",
    "        #dataset\n",
    "        self.jaad_dataset = '../../../../data/smailait-data/jaad/annotations'\n",
    "        self.dtype = 'train'\n",
    "        self.from_file = True\n",
    "        self.file = '/data/smailait-data/train_crossing.csv'\n",
    "        self.seq_len = 18\n",
    "        self.predicted_seq_len = 18\n",
    "        self.crop = 0.3\n",
    "        self.activity_h = 9\n",
    "        self.activity_w = 16\n",
    "        self.truncate = 0\n",
    "        self.final_frame_offset = 0\n",
    "        self.loader_workers = 8\n",
    "        self.loader_shuffle = True\n",
    "        self.pin_memory = False\n",
    "        self.image_resize = [240, 426]\n",
    "        self.image_size = [1080, 1920]\n",
    "        self.device='cuda'\n",
    "        \n",
    "args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PS_PIE(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(PS_PIE, self).__init__()\n",
    "\n",
    "        self.speed_encoder = nn.LSTM(input_size=4, hidden_size=256)\n",
    "        self.pos_encoder   = nn.LSTM(input_size=4, hidden_size=256)\n",
    "\n",
    "        self.pos_embedding = nn.Sequential(nn.Linear(in_features=2, out_features=4),\n",
    "                                           nn.ReLU())\n",
    "\n",
    "        self.crossing_decoder = nn.LSTMCell(input_size=4, hidden_size=256)\n",
    "\n",
    "        self.fc_crossing = nn.Sequential(nn.Linear(in_features=256, out_features=2),\n",
    "                                         nn.ReLU())\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.args = args\n",
    "        \n",
    "    def forward(self, speed=None, pos=None):\n",
    "\n",
    "        _, (hsp, csp) = self.speed_encoder(speed.permute(1,0,2))\n",
    "        hsp = hsp.squeeze(0)\n",
    "        csp = csp.squeeze(0)\n",
    "\n",
    "        _, (hpo, cpo) = self.pos_encoder(pos.permute(1,0,2))\n",
    "        crossing_outputs = torch.tensor([], device='cuda')\n",
    "        in_cr = pos[:,-1,:]\n",
    "        hpo = hpo.squeeze(0)\n",
    "        cpo = cpo.squeeze(0)\n",
    "        #hdc = torch.cat((hpo, hsp), dim=1)\n",
    "        #cdc = torch.cat((cpo, csp), dim=1)\n",
    "        hdc = hpo+hsp\n",
    "        cdc = cpo+csp\n",
    "        for i in range(8):\n",
    "            hdc, cdc         = self.crossing_decoder(in_cr, (hdc, cdc))\n",
    "            in_cr            = self.pos_embedding(self.fc_crossing(hdc))\n",
    "            crossing_output  = self.softmax(self.fc_crossing(hdc))\n",
    "            crossing_outputs = torch.cat((crossing_outputs, crossing_output.unsqueeze(1)), dim = 1)\n",
    "\n",
    "        return crossing_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PS_PIE(args).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame\n",
      "crossing_true\n",
      "imagefolderpath\n",
      "scenefolderpath\n",
      "filename\n",
      "file\n",
      "bounding_box\n",
      "im_size\n",
      "future_bounding_box\n",
      "future_crossing\n",
      "train  loaded\n",
      "frame\n",
      "crossing_true\n",
      "imagefolderpath\n",
      "scenefolderpath\n",
      "filename\n",
      "file\n",
      "bounding_box\n",
      "im_size\n",
      "future_bounding_box\n",
      "future_crossing\n",
      "train  loaded\n",
      "frame\n",
      "crossing_true\n",
      "imagefolderpath\n",
      "scenefolderpath\n",
      "filename\n",
      "file\n",
      "bounding_box\n",
      "im_size\n",
      "future_bounding_box\n",
      "future_crossing\n",
      "val  loaded\n"
     ]
    }
   ],
   "source": [
    "train, val, test = DataLoader_PIE.data_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate  = 0.00001\n",
    "optimizer     = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "scheduler      = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, threshold = 1e-8, verbose=True)\n",
    "mse            = nn.MSELoss()\n",
    "bce            = nn.BCELoss()\n",
    "train_s_scores = []\n",
    "train_c_scores = []\n",
    "val_s_scores   = []\n",
    "val_c_scores   = []\n",
    "log            = open('log_PS_PIE.txt', 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 1  | tc_l: 0.5435552312930425  | vc_l: 0.4537753471914603  | acc: 0.7754464285714286  | rec: 0.8464154609562773 | t:23.0591\n",
      "e: 2  | tc_l: 0.36274482009808223  | vc_l: 0.3894284483121366  | acc: 0.8430484693877549  | rec: 0.7316322475920848 | t:21.9644\n",
      "e: 3  | tc_l: 0.32376628439625105  | vc_l: 0.3727226610086402  | acc: 0.849170918367347  | rec: 0.7493893440524327 | t:21.5668\n",
      "e: 4  | tc_l: 0.3039538821180662  | vc_l: 0.3579064245734896  | acc: 0.8531887755102038  | rec: 0.7244736953586774 | t:18.8294\n",
      "e: 5  | tc_l: 0.28493862058719  | vc_l: 0.3432806999403603  | acc: 0.8554846938775507  | rec: 0.7112354430391106 | t:19.7702\n",
      "e: 6  | tc_l: 0.26965628296136857  | vc_l: 0.3363522778512264  | acc: 0.8598214285714281  | rec: 0.7147601237306285 | t:18.9706\n",
      "e: 7  | tc_l: 0.25894700350860755  | vc_l: 0.3288443851835874  | acc: 0.864732142857143  | rec: 0.7432191385996343 | t:21.9631\n",
      "e: 8  | tc_l: 0.2515563983817895  | vc_l: 0.32659539299047724  | acc: 0.866517857142857  | rec: 0.7416015399571898 | t:21.4755\n",
      "e: 9  | tc_l: 0.24572055458525816  | vc_l: 0.3218224104873988  | acc: 0.8688137755102039  | rec: 0.7415930560717441 | t:21.2245\n",
      "e: 10  | tc_l: 0.24118702345589796  | vc_l: 0.31972738066498113  | acc: 0.8690688775510202  | rec: 0.7446452489950478 | t:21.7230\n",
      "e: 11  | tc_l: 0.23701891441146533  | vc_l: 0.3166477981270576  | acc: 0.871364795918367  | rec: 0.7550662697986485 | t:22.5692\n",
      "e: 12  | tc_l: 0.23370004946986833  | vc_l: 0.3177403623656351  | acc: 0.8714285714285713  | rec: 0.732964017625162 | t:20.6214\n",
      "e: 13  | tc_l: 0.23080324810743333  | vc_l: 0.3129068339357571  | acc: 0.8739158163265306  | rec: 0.7345648428320173 | t:21.0469\n",
      "e: 14  | tc_l: 0.22789513108134268  | vc_l: 0.31630377045699526  | acc: 0.8717474489795918  | rec: 0.7471370020505517 | t:21.9184\n",
      "e: 15  | tc_l: 0.22587899934500455  | vc_l: 0.3073283812905453  | acc: 0.8783163265306121  | rec: 0.7476442628169807 | t:21.5301\n",
      "e: 16  | tc_l: 0.22347840431829294  | vc_l: 0.3063063214019853  | acc: 0.8785714285714287  | rec: 0.7544540867824382 | t:21.5039\n",
      "e: 17  | tc_l: 0.2214357524762551  | vc_l: 0.3071389265206395  | acc: 0.8745535714285714  | rec: 0.7354362802637704 | t:21.4207\n",
      "e: 18  | tc_l: 0.2194738209446271  | vc_l: 0.30387486532634617  | acc: 0.8783163265306121  | rec: 0.7647933707734917 | t:21.4471\n",
      "e: 19  | tc_l: 0.21808619162191947  | vc_l: 0.30357143153645555  | acc: 0.8792729591836737  | rec: 0.7637318306754589 | t:21.1935\n",
      "e: 20  | tc_l: 0.21644662121931713  | vc_l: 0.3034753854177436  | acc: 0.8796556122448982  | rec: 0.7575225325255218 | t:21.7620\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-06.\n",
      "e: 21  | tc_l: 0.21497468710194031  | vc_l: 0.30437912715941057  | acc: 0.8791454081632651  | rec: 0.7635367146417563 | t:22.4477\n",
      "e: 22  | tc_l: 0.2123962508291006  | vc_l: 0.30259140177953  | acc: 0.8805484693877557  | rec: 0.7594102702611704 | t:21.6601\n",
      "e: 23  | tc_l: 0.2120789933403333  | vc_l: 0.30164133324002734  | acc: 0.8804209183673478  | rec: 0.7638405411736537 | t:21.4656\n",
      "e: 24  | tc_l: 0.21186709728340308  | vc_l: 0.302938205323049  | acc: 0.87984693877551  | rec: 0.7486697257207902 | t:22.3296\n",
      "e: 25  | tc_l: 0.21155160119136174  | vc_l: 0.30339076012677074  | acc: 0.8798469387755103  | rec: 0.7762735922623127 | t:22.5342\n",
      "e: 26  | tc_l: 0.21150580584009487  | vc_l: 0.30287126489743893  | acc: 0.8802295918367344  | rec: 0.7711533038026641 | t:22.3487\n",
      "e: 27  | tc_l: 0.21137452098478873  | vc_l: 0.30245095805017924  | acc: 0.8805484693877551  | rec: 0.7726923974586426 | t:22.1511\n",
      "e: 28  | tc_l: 0.21123663287361463  | vc_l: 0.30255305090424967  | acc: 0.8801020408163264  | rec: 0.7691329084180598 | t:21.3210\n",
      "e: 29  | tc_l: 0.2110677758703629  | vc_l: 0.3033107838460377  | acc: 0.8798469387755101  | rec: 0.7718083857045446 | t:21.8471\n",
      "e: 30  | tc_l: 0.21095153566201527  | vc_l: 0.3020310772925007  | acc: 0.8802295918367345  | rec: 0.7702301986382107 | t:21.1627\n",
      "e: 31  | tc_l: 0.21075622916718323  | vc_l: 0.303983241471709  | acc: 0.8792729591836738  | rec: 0.7434812315911921 | t:22.5800\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-07.\n",
      "e: 32  | tc_l: 0.21066004980603853  | vc_l: 0.3038608827913294  | acc: 0.8799744897959182  | rec: 0.7459623126882017 | t:21.9926\n",
      "e: 33  | tc_l: 0.21031403758376838  | vc_l: 0.3008606388252609  | acc: 0.8809948979591837  | rec: 0.7719186263149114 | t:22.2173\n",
      "e: 34  | tc_l: 0.21029915789266426  | vc_l: 0.3032822364142963  | acc: 0.8799107142857148  | rec: 0.7645078711462456 | t:21.6921\n",
      "e: 35  | tc_l: 0.21012955877929926  | vc_l: 0.2997509003141705  | acc: 0.8808673469387757  | rec: 0.7614492946883514 | t:21.7439\n",
      "e: 36  | tc_l: 0.21026528361191352  | vc_l: 0.3029009667130149  | acc: 0.8805484693877551  | rec: 0.7713426450577064 | t:21.5241\n",
      "e: 37  | tc_l: 0.21023886959254742  | vc_l: 0.302740003685562  | acc: 0.8805484693877549  | rec: 0.7559768912304403 | t:21.9274\n",
      "e: 38  | tc_l: 0.21022048323353132  | vc_l: 0.302926347952108  | acc: 0.8802933673469391  | rec: 0.7394271850747297 | t:22.6191\n",
      "e: 39  | tc_l: 0.21021854113042354  | vc_l: 0.3029337630284076  | acc: 0.8802295918367349  | rec: 0.7779527781347979 | t:21.6772\n",
      "e: 40  | tc_l: 0.2102012445429961  | vc_l: 0.30333164972918375  | acc: 0.8801020408163263  | rec: 0.746275450912675 | t:21.8445\n",
      "e: 41  | tc_l: 0.2101921056136489  | vc_l: 0.3027889758196412  | acc: 0.8805484693877554  | rec: 0.7565902957740619 | t:21.7244\n",
      "e: 42  | tc_l: 0.21015980232010284  | vc_l: 0.3027588091790676  | acc: 0.8801020408163265  | rec: 0.7812130145903892 | t:22.3451\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-08.\n",
      "e: 43  | tc_l: 0.21016115343074004  | vc_l: 0.30321693253152227  | acc: 0.8804209183673468  | rec: 0.7678299975823766 | t:22.2914\n",
      "e: 44  | tc_l: 0.2101251858000954  | vc_l: 0.3031860467958815  | acc: 0.8802933673469386  | rec: 0.7724753473198802 | t:22.0329\n",
      "e: 45  | tc_l: 0.21010847871005536  | vc_l: 0.3026301598518479  | acc: 0.8807397959183674  | rec: 0.7597929256144308 | t:21.4042\n",
      "e: 46  | tc_l: 0.21011823487033446  | vc_l: 0.30289802464599513  | acc: 0.8802295918367349  | rec: 0.7765857021331708 | t:21.7571\n",
      "e: 47  | tc_l: 0.21000244422256947  | vc_l: 0.3006079214415988  | acc: 0.881122448979592  | rec: 0.7579005805820273 | t:21.4925\n",
      "e: 48  | tc_l: 0.21001780529816946  | vc_l: 0.3016305891987012  | acc: 0.881186224489796  | rec: 0.7540189810871113 | t:22.1220\n",
      "e: 49  | tc_l: 0.21008682149772842  | vc_l: 0.30342489214880125  | acc: 0.8801658163265306  | rec: 0.7695747663357411 | t:21.9998\n",
      "e: 50  | tc_l: 0.21010377838710945  | vc_l: 0.30260556921058773  | acc: 0.8809948979591841  | rec: 0.7803494750484361 | t:21.8579\n",
      "e: 51  | tc_l: 0.21011103748281798  | vc_l: 0.3005767228195862  | acc: 0.8815688775510204  | rec: 0.7305300863436722 | t:21.7373\n",
      "e: 52  | tc_l: 0.21011181761076053  | vc_l: 0.3035720519873561  | acc: 0.8800382653061222  | rec: 0.7727536240531406 | t:21.4130\n",
      "e: 53  | tc_l: 0.21011364113291103  | vc_l: 0.3017162393246378  | acc: 0.8808673469387754  | rec: 0.7658060967683246 | t:22.1102\n",
      "e: 54  | tc_l: 0.21011248239378136  | vc_l: 0.30106557879064766  | acc: 0.8808035714285712  | rec: 0.7637949175152565 | t:21.7952\n",
      "e: 55  | tc_l: 0.21011118689676125  | vc_l: 0.3028232753276825  | acc: 0.8806122448979594  | rec: 0.7715654018645244 | t:22.0574\n",
      "e: 56  | tc_l: 0.21007676645368337  | vc_l: 0.3030649261663155  | acc: 0.8801658163265307  | rec: 0.7565260573322674 | t:21.0331\n",
      "e: 57  | tc_l: 0.2101085286339124  | vc_l: 0.3026894103659659  | acc: 0.8801658163265311  | rec: 0.7635866391128827 | t:22.0084\n",
      "e: 58  | tc_l: 0.21010162746409575  | vc_l: 0.3013475411856661  | acc: 0.8811224489795924  | rec: 0.7705470718305326 | t:21.5338\n",
      "e: 59  | tc_l: 0.21010577297210695  | vc_l: 0.3028360581671705  | acc: 0.8801020408163267  | rec: 0.763488827894158 | t:22.7567\n",
      "e: 60  | tc_l: 0.21010209437211355  | vc_l: 0.3036189454094488  | acc: 0.8800382653061224  | rec: 0.7573369157979315 | t:22.8226\n",
      "e: 61  | tc_l: 0.21010247075061003  | vc_l: 0.30133938188759646  | acc: 0.8812500000000003  | rec: 0.7429316977404388 | t:21.7486\n",
      "e: 62  | tc_l: 0.21010039841135342  | vc_l: 0.30239368693865076  | acc: 0.8810586734693875  | rec: 0.7635026342868083 | t:21.2800\n",
      "e: 63  | tc_l: 0.21009993806978067  | vc_l: 0.30175178494228394  | acc: 0.8811224489795918  | rec: 0.7384246637661854 | t:22.2815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 64  | tc_l: 0.2100987055550019  | vc_l: 0.30287218101474706  | acc: 0.8805484693877553  | rec: 0.761827734375072 | t:21.9834\n",
      "e: 65  | tc_l: 0.2100969303722183  | vc_l: 0.30124211326545597  | acc: 0.8808673469387756  | rec: 0.7788840555994748 | t:22.2678\n",
      "e: 66  | tc_l: 0.20992138180633385  | vc_l: 0.30250831974708303  | acc: 0.8805484693877554  | rec: 0.7563526891998288 | t:21.6292\n",
      "e: 67  | tc_l: 0.21003670470416547  | vc_l: 0.3022219538308528  | acc: 0.8805484693877556  | rec: 0.7625357159215717 | t:22.5915\n",
      "e: 68  | tc_l: 0.21003542559593916  | vc_l: 0.3008655367457137  | acc: 0.8817602040816327  | rec: 0.7496382740708604 | t:22.0255\n",
      "e: 69  | tc_l: 0.21009245137373606  | vc_l: 0.30276024562059617  | acc: 0.8805484693877553  | rec: 0.7541740446914785 | t:20.7522\n",
      "e: 70  | tc_l: 0.20997826381772758  | vc_l: 0.3029889068281164  | acc: 0.8803571428571427  | rec: 0.7649927683804943 | t:21.9994\n",
      "e: 71  | tc_l: 0.21008977496623993  | vc_l: 0.30176448605346434  | acc: 0.8815051020408167  | rec: 0.7817481966385965 | t:21.5685\n",
      "e: 72  | tc_l: 0.2100837876026829  | vc_l: 0.30263950493262737  | acc: 0.8805484693877549  | rec: 0.7673811801905212 | t:22.7880\n",
      "e: 73  | tc_l: 0.21008674842864275  | vc_l: 0.3019951569790743  | acc: 0.8806760204081633  | rec: 0.7687097373087884 | t:21.3952\n",
      "e: 74  | tc_l: 0.21008617303396265  | vc_l: 0.30267699587405944  | acc: 0.8806122448979593  | rec: 0.7629881766880761 | t:21.7553\n",
      "e: 75  | tc_l: 0.21008454558998346  | vc_l: 0.3033868118132256  | acc: 0.8799744897959185  | rec: 0.7741232956582338 | t:22.0418\n",
      "e: 76  | tc_l: 0.2100829592992862  | vc_l: 0.30218876297680697  | acc: 0.8809948979591838  | rec: 0.7651717840928087 | t:21.2211\n",
      "e: 77  | tc_l: 0.21008015615741413  | vc_l: 0.2997269936818249  | acc: 0.8810586734693876  | rec: 0.7683829181141362 | t:22.2297\n",
      "e: 78  | tc_l: 0.2100799427976211  | vc_l: 0.3028017905141626  | acc: 0.8804209183673473  | rec: 0.7760106840844857 | t:21.8766\n",
      "e: 79  | tc_l: 0.210079483071963  | vc_l: 0.3009530460195882  | acc: 0.8813775510204083  | rec: 0.7673443666431039 | t:20.5365\n",
      "e: 80  | tc_l: 0.2100772319411238  | vc_l: 0.30263588440661526  | acc: 0.880229591836735  | rec: 0.7603302875638752 | t:21.5053\n",
      "e: 81  | tc_l: 0.2100768943876028  | vc_l: 0.3027188496626153  | acc: 0.8804846938775513  | rec: 0.7776346085931612 | t:21.0808\n",
      "e: 82  | tc_l: 0.2100132307857275  | vc_l: 0.3029015805496245  | acc: 0.8799744897959182  | rec: 0.762693681704708 | t:22.1592\n",
      "e: 83  | tc_l: 0.2100408654138446  | vc_l: 0.3020742134172089  | acc: 0.881186224489796  | rec: 0.751929163082984 | t:22.0056\n",
      "e: 84  | tc_l: 0.21001269702613354  | vc_l: 0.3019984921782601  | acc: 0.8805484693877546  | rec: 0.7518500559402481 | t:22.2371\n",
      "e: 85  | tc_l: 0.21007157192130885  | vc_l: 0.30331699413304425  | acc: 0.8800382653061224  | rec: 0.7580912234639033 | t:21.5968\n",
      "e: 86  | tc_l: 0.21006907831132413  | vc_l: 0.3034148622988438  | acc: 0.8800382653061225  | rec: 0.7705499634533433 | t:21.7382\n",
      "e: 87  | tc_l: 0.21006895062327385  | vc_l: 0.30251803940960337  | acc: 0.880548469387755  | rec: 0.7734735770706455 | t:22.4048\n",
      "e: 88  | tc_l: 0.2100668424492081  | vc_l: 0.3004714877021556  | acc: 0.8815051020408164  | rec: 0.7597303452221985 | t:21.4025\n",
      "e: 89  | tc_l: 0.21006602850556375  | vc_l: 0.30304405070385154  | acc: 0.880420918367347  | rec: 0.7620780886292275 | t:20.0769\n",
      "e: 90  | tc_l: 0.21005143704017004  | vc_l: 0.2997749091259071  | acc: 0.881887755102041  | rec: 0.7762479235026138 | t:18.3056\n",
      "e: 91  | tc_l: 0.2100615672369798  | vc_l: 0.3011129087179291  | acc: 0.8812499999999999  | rec: 0.7749148480560013 | t:18.1988\n",
      "e: 92  | tc_l: 0.2100531067661941  | vc_l: 0.30182203642871913  | acc: 0.8806760204081631  | rec: 0.7629381538343271 | t:18.2683\n",
      "e: 93  | tc_l: 0.21002473826706408  | vc_l: 0.3022619057066587  | acc: 0.8804846938775506  | rec: 0.7525289122056046 | t:17.2809\n",
      "e: 94  | tc_l: 0.21002796583622693  | vc_l: 0.3029166177219274  | acc: 0.880484693877551  | rec: 0.7838951185109301 | t:17.6806\n",
      "e: 95  | tc_l: 0.21005869859457016  | vc_l: 0.30160823046248786  | acc: 0.8809948979591834  | rec: 0.7584402181733854 | t:19.4505\n",
      "e: 96  | tc_l: 0.21005690345416467  | vc_l: 0.3029711182628359  | acc: 0.8803571428571425  | rec: 0.7398765154374326 | t:18.4811\n",
      "e: 97  | tc_l: 0.20998732896149158  | vc_l: 0.3023457896648621  | acc: 0.8804209183673469  | rec: 0.7687984509724572 | t:17.9765\n",
      "e: 98  | tc_l: 0.21005318519473076  | vc_l: 0.30315720723295697  | acc: 0.8801658163265302  | rec: 0.7737840590527458 | t:17.7275\n",
      "e: 99  | tc_l: 0.21004478054990372  | vc_l: 0.2988773035455723  | acc: 0.8822704081632654  | rec: 0.7542863207016808 | t:18.1787\n",
      "e: 100  | tc_l: 0.21005194469044605  | vc_l: 0.3013742756174535  | acc: 0.8808673469387756  | rec: 0.7758137908561905 | t:18.4821\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    start = time.time()\n",
    "\n",
    "    avg_epoch_train_c_loss = 0\n",
    "    avg_epoch_val_c_loss   = 0\n",
    "    avg_acc = 0\n",
    "    avg_rec = 0\n",
    "    \n",
    "    counter = 0\n",
    "    for idx, (obs_s, _, obs_p, _, target_c) in enumerate(train):\n",
    "        counter += 1\n",
    "        obs_s    = obs_s.type(torch.float32).to(device='cuda')\n",
    "        obs_p    = obs_p.type(torch.float32).to(device='cuda')\n",
    "        target_c = target_c.type(torch.float32).to(device='cuda')\n",
    "        \n",
    "        net.zero_grad()\n",
    "        crossing_preds = net(speed=obs_s, pos=obs_p)\n",
    "        crossing_loss = 0\n",
    "        for i in range(8):\n",
    "            crossing_loss += bce(crossing_preds[:,i,:], target_c[:,i,:])\n",
    "        crossing_loss /= 8\n",
    "        crossing_loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_epoch_train_c_loss += float(crossing_loss)\n",
    "\n",
    "    avg_epoch_train_c_loss/=counter\n",
    "    train_c_scores.append(avg_epoch_train_c_loss)\n",
    "    \n",
    "    counter=0\n",
    "    for idx, (obs_s, _, obs_p, _, target_c) in enumerate(test):\n",
    "        counter+=1\n",
    "        obs_s    = obs_s.type(torch.float32).to(device='cuda')\n",
    "        obs_p    = obs_p.type(torch.float32).to(device='cuda')\n",
    "        target_c = target_c.type(torch.float32).to(device='cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            crossing_preds = net(speed=obs_s, pos=obs_p)\n",
    "            crossing_loss = 0\n",
    "            for i in range(8):\n",
    "                crossing_loss += bce(crossing_preds[:,i,:], target_c[:,i,:])\n",
    "            crossing_loss /= 8\n",
    "            avg_epoch_val_c_loss += float(crossing_loss)\n",
    "            #avg_acc += float(torch.sum(nn.Threshold(0.,0.)(nn.Threshold(-0.5, 1.)(-1*crossing_preds[:,:,0]))==target_c[:,:-1,0]).type(torch.float32)/(20*8))\n",
    "            avg_rec += recall_score(nn.Threshold(0.,0.)(nn.Threshold(-0.5, 1.)(-1*crossing_preds[:,:,0])).reshape(-1).detach().cpu().numpy(), target_c[:,:-1,0].reshape(-1).cpu().numpy(), average='binary', zero_division=1)\n",
    "            avg_acc += accuracy_score(nn.Threshold(0.,0.)(nn.Threshold(-0.5, 1.)(-1*crossing_preds[:,:,0])).reshape(-1).detach().cpu().numpy(), target_c[:,:-1,0].reshape(-1).cpu().numpy())\n",
    "        \n",
    "    avg_epoch_val_c_loss/=counter\n",
    "    avg_acc/=counter\n",
    "    avg_rec/=counter\n",
    "    val_c_scores.append(avg_epoch_val_c_loss)\n",
    "    \n",
    "    scheduler.step(crossing_loss)\n",
    "    \n",
    "    print('e:', epoch, ' | tc_l:', avg_epoch_train_c_loss, ' | vc_l:', avg_epoch_val_c_loss,' | acc:', avg_acc,' | rec:', avg_rec,\n",
    "          '| t:%.4f'%(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 100  | tc_l: 0.21005194469044605  | vc_l: 0.3045199844018424  | acc: 0.8899383972664453  | rec: 0.7619282550614257 | t:19925.3827\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for idx, (obs_s, _, obs_p, _, target_c) in enumerate(test):\n",
    "    counter+=1\n",
    "    obs_s    = obs_s.type(torch.float32).to(device='cuda')\n",
    "    obs_p    = obs_p.type(torch.float32).to(device='cuda')\n",
    "    target_c = target_c.type(torch.float32).to(device='cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        crossing_preds = net(speed=obs_s, pos=obs_p)\n",
    "        crossing_loss = 0\n",
    "        for i in range(8):\n",
    "            crossing_loss += bce(crossing_preds[:,i,:], target_c[:,i,:])\n",
    "        crossing_loss /= 8\n",
    "        avg_epoch_val_c_loss += float(crossing_loss)\n",
    "        avg_rec += recall_score(nn.Threshold(0.,0.)(nn.Threshold(-0.5, 1.)(-1*crossing_preds[:,:,0])).reshape(-1).detach().cpu().numpy(), target_c[:,:-1,0].reshape(-1).cpu().numpy(), average='binary', zero_division=1)\n",
    "        avg_acc += accuracy_score(nn.Threshold(0.,0.)(nn.Threshold(-0.5, 1.)(-1*crossing_preds[:,:,0])).reshape(-1).detach().cpu().numpy(), target_c[:,:-1,0].reshape(-1).cpu().numpy())\n",
    "        \n",
    "avg_epoch_val_c_loss/=counter\n",
    "avg_acc/=counter\n",
    "avg_rec/=counter\n",
    "val_c_scores.append(avg_epoch_val_c_loss)\n",
    "\n",
    "#scheduler.step(crossing_loss)\n",
    "\n",
    "print('e:', epoch, ' | tc_l:', avg_epoch_train_c_loss, ' | vc_l:', avg_epoch_val_c_loss,' | acc:', avg_acc,' | rec:', avg_rec,\n",
    "      '| t:%.4f'%(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
