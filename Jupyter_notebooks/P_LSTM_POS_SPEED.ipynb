{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from DataLoader_P_speed.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import import_ipynb\n",
    "import DataLoader_P_speed\n",
    "import utils\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        self.base_out_features = 2048\n",
    "        self.t_obs = 8\n",
    "        self.batch_size = 20\n",
    "        self.scene_shape = [3, 144, 256]\n",
    "        self.base_shape = [2048, 9, 16]\n",
    "        self.hidden_size = 128\n",
    "        self.embedding_size = 64\n",
    "        self.input_size = 2\n",
    "        self.output_size = 2\n",
    "        self.sample = True\n",
    "        self.n_train_sequences = 15000\n",
    "        self.n_val_sequences = 10\n",
    "        self.trainOrVal = 'train'\n",
    "        args.citywalks = False\n",
    "        \n",
    "        #dataset\n",
    "        self.jaad_dataset = '../../../../data/smailait-data/jaad/annotations'\n",
    "        self.dtype = 'train'\n",
    "        self.from_file = True\n",
    "        self.file = '/data/smailait-data/train_speed.csv'\n",
    "        self.val_file = '/data/smailait-data/val_speed.csv'\n",
    "        self.seq_len = 4\n",
    "        self.predicted_seq_len = 4\n",
    "        self.crop = 0.3\n",
    "        self.activity_h = 9\n",
    "        self.activity_w = 16\n",
    "        self.truncate = 0\n",
    "        self.final_frame_offset = 0\n",
    "        self.loader_workers = 20\n",
    "        self.loader_shuffle = True\n",
    "        self.pin_memory = False\n",
    "        self.image_resize = [144, 256]\n",
    "        self.image_size = [1080, 1920]\n",
    "        self.device='cuda'\n",
    "        \n",
    "args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(P_LSTM, self).__init__()\n",
    "        \n",
    "        self.pos_encoder = nn.LSTM(input_size=4, hidden_size=256)\n",
    "        \n",
    "        self.speed_encoder = nn.LSTM(input_size=4, hidden_size=256)\n",
    "        \n",
    "        self.decoder = nn.LSTMCell(input_size=4, hidden_size=256)\n",
    "        \n",
    "        self.out = nn.Linear(in_features=256, out_features=4)\n",
    "        \n",
    "        self.activation = nn.Hardtanh(min_val=-100, max_val=100)\n",
    "        \n",
    "    def forward(self, pos, speed):\n",
    "        _, (hp, cp) = self.pos_encoder(pos.permute(1,0,2))\n",
    "        _, (hs, cs) = self.speed_encoder(speed.permute(1,0,2))\n",
    "        \n",
    "        outputs = torch.tensor([], device='cuda')\n",
    "        in_dec = speed[:,-1,:]\n",
    "        \n",
    "        hp = hp.squeeze(0)\n",
    "        cp = cp.squeeze(0)\n",
    "        hs = hs.squeeze(0)\n",
    "        cs = cs.squeeze(0)\n",
    "        #hd = torch.cat((hp, hs), dim=1)\n",
    "        #cd = torch.cat((cp, cs), dim=1)\n",
    "        hd = hp+hs\n",
    "        cd = cp+hs\n",
    "        for i in range(8):\n",
    "            hd, cd = self.decoder(in_dec, (hd, cd))\n",
    "            output = self.activation(self.out(hd))\n",
    "            outputs = torch.cat((outputs, output.unsqueeze(1)), dim = 1)\n",
    "            in_dec = output.detach()\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = P_LSTM().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame\n",
      "crossing_true\n",
      "imagefolderpath\n",
      "scenefolderpath\n",
      "filename\n",
      "file\n",
      "bounding_box\n",
      "im_size\n",
      "future_bounding_box\n",
      "train  loaded\n",
      "frame\n",
      "crossing_true\n",
      "imagefolderpath\n",
      "scenefolderpath\n",
      "filename\n",
      "file\n",
      "bounding_box\n",
      "im_size\n",
      "future_bounding_box\n",
      "train  loaded\n",
      "frame\n",
      "crossing_true\n",
      "imagefolderpath\n",
      "scenefolderpath\n",
      "filename\n",
      "file\n",
      "bounding_box\n",
      "im_size\n",
      "future_bounding_box\n",
      "val  loaded\n"
     ]
    }
   ],
   "source": [
    "train, val, test = DataLoader_P_speed.data_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, threshold = 1e-8, verbose=True)\n",
    "criterion = nn.MSELoss()\n",
    "train_scores = []\n",
    "val_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 0  | train_loss: 2.5565  | val_loss: 2.4496 | ade: 12.0830 | fde: 20.9679 | aiou: 0.7138 | fiou: 0.5709\n",
      "e: 1  | train_loss: 1.7650  | val_loss: 2.1944 | ade: 10.5242 | fde: 17.9144 | aiou: 0.7268 | fiou: 0.5868\n",
      "e: 2  | train_loss: 1.6114  | val_loss: 2.1044 | ade: 9.7829 | fde: 16.3339 | aiou: 0.7427 | fiou: 0.6183\n",
      "e: 3  | train_loss: 1.5412  | val_loss: 2.0453 | ade: 9.6274 | fde: 16.0304 | aiou: 0.7447 | fiou: 0.6217\n",
      "e: 4  | train_loss: 1.4893  | val_loss: 2.0080 | ade: 9.5139 | fde: 15.7917 | aiou: 0.7446 | fiou: 0.6213\n",
      "e: 5  | train_loss: 1.4470  | val_loss: 1.9606 | ade: 9.4586 | fde: 15.7702 | aiou: 0.7439 | fiou: 0.6199\n",
      "e: 6  | train_loss: 1.4079  | val_loss: 1.9218 | ade: 9.3626 | fde: 15.4703 | aiou: 0.7467 | fiou: 0.6278\n",
      "e: 7  | train_loss: 1.3586  | val_loss: 1.8705 | ade: 9.4645 | fde: 15.8960 | aiou: 0.7411 | fiou: 0.6165\n",
      "e: 8  | train_loss: 1.3025  | val_loss: 1.8064 | ade: 9.4806 | fde: 15.8639 | aiou: 0.7443 | fiou: 0.6247\n",
      "e: 9  | train_loss: 1.2586  | val_loss: 1.7590 | ade: 9.4216 | fde: 15.7594 | aiou: 0.7421 | fiou: 0.6213\n",
      "e: 10  | train_loss: 1.2188  | val_loss: 1.7391 | ade: 9.3338 | fde: 15.5615 | aiou: 0.7457 | fiou: 0.6271\n",
      "e: 11  | train_loss: 1.1899  | val_loss: 1.6950 | ade: 9.2577 | fde: 15.4576 | aiou: 0.7471 | fiou: 0.6274\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0000e-05.\n",
      "e: 12  | train_loss: 1.1708  | val_loss: 1.7138 | ade: 9.3229 | fde: 15.6245 | aiou: 0.7436 | fiou: 0.6220\n",
      "e: 13  | train_loss: 1.1369  | val_loss: 1.7012 | ade: 9.3267 | fde: 15.5766 | aiou: 0.7463 | fiou: 0.6255\n",
      "e: 14  | train_loss: 1.1228  | val_loss: 1.6781 | ade: 9.2181 | fde: 15.3019 | aiou: 0.7485 | fiou: 0.6300\n",
      "e: 15  | train_loss: 1.1131  | val_loss: 1.6747 | ade: 9.3110 | fde: 15.5326 | aiou: 0.7463 | fiou: 0.6258\n",
      "e: 16  | train_loss: 1.1021  | val_loss: 1.6648 | ade: 9.2305 | fde: 15.2873 | aiou: 0.7498 | fiou: 0.6329\n",
      "e: 17  | train_loss: 1.0919  | val_loss: 1.6682 | ade: 9.2272 | fde: 15.3889 | aiou: 0.7475 | fiou: 0.6262\n",
      "e: 18  | train_loss: 1.0836  | val_loss: 1.6641 | ade: 9.2876 | fde: 15.4122 | aiou: 0.7489 | fiou: 0.6305\n",
      "e: 19  | train_loss: 1.0754  | val_loss: 1.6498 | ade: 9.2344 | fde: 15.4807 | aiou: 0.7481 | fiou: 0.6263\n",
      "e: 20  | train_loss: 1.0671  | val_loss: 1.6540 | ade: 9.1361 | fde: 15.1574 | aiou: 0.7513 | fiou: 0.6340\n",
      "e: 21  | train_loss: 1.0580  | val_loss: 1.6721 | ade: 9.3200 | fde: 15.5511 | aiou: 0.7473 | fiou: 0.6269\n",
      "e: 22  | train_loss: 1.0489  | val_loss: 1.6575 | ade: 9.1762 | fde: 15.2119 | aiou: 0.7504 | fiou: 0.6337\n",
      "e: 23  | train_loss: 1.0424  | val_loss: 1.6724 | ade: 9.3750 | fde: 15.7734 | aiou: 0.7445 | fiou: 0.6198\n",
      "e: 24  | train_loss: 1.0341  | val_loss: 1.6790 | ade: 9.4619 | fde: 15.7855 | aiou: 0.7452 | fiou: 0.6227\n",
      "e: 25  | train_loss: 1.0272  | val_loss: 1.6461 | ade: 9.1573 | fde: 15.2887 | aiou: 0.7496 | fiou: 0.6290\n",
      "Epoch    26: reducing learning rate of group 0 to 2.5000e-05.\n",
      "e: 26  | train_loss: 1.0195  | val_loss: 1.6780 | ade: 9.2498 | fde: 15.4499 | aiou: 0.7476 | fiou: 0.6267\n",
      "e: 27  | train_loss: 1.0008  | val_loss: 1.6686 | ade: 9.1821 | fde: 15.2870 | aiou: 0.7509 | fiou: 0.6323\n",
      "e: 28  | train_loss: 0.9960  | val_loss: 1.6303 | ade: 9.1633 | fde: 15.2423 | aiou: 0.7496 | fiou: 0.6296\n",
      "e: 29  | train_loss: 0.9906  | val_loss: 1.6315 | ade: 9.1658 | fde: 15.2494 | aiou: 0.7496 | fiou: 0.6303\n",
      "e: 30  | train_loss: 0.9862  | val_loss: 1.6624 | ade: 9.1856 | fde: 15.2869 | aiou: 0.7502 | fiou: 0.6309\n",
      "e: 31  | train_loss: 0.9816  | val_loss: 1.6617 | ade: 9.1694 | fde: 15.2600 | aiou: 0.7506 | fiou: 0.6317\n",
      "e: 32  | train_loss: 0.9772  | val_loss: 1.6617 | ade: 9.2534 | fde: 15.4158 | aiou: 0.7486 | fiou: 0.6282\n",
      "e: 33  | train_loss: 0.9741  | val_loss: 1.6675 | ade: 9.2400 | fde: 15.4061 | aiou: 0.7484 | fiou: 0.6271\n",
      "e: 34  | train_loss: 0.9695  | val_loss: 1.6554 | ade: 9.1797 | fde: 15.3084 | aiou: 0.7498 | fiou: 0.6296\n",
      "e: 35  | train_loss: 0.9664  | val_loss: 1.6627 | ade: 9.2310 | fde: 15.3928 | aiou: 0.7475 | fiou: 0.6269\n",
      "e: 36  | train_loss: 0.9623  | val_loss: 1.6568 | ade: 9.2078 | fde: 15.3070 | aiou: 0.7493 | fiou: 0.6289\n",
      "e: 37  | train_loss: 0.9574  | val_loss: 1.6454 | ade: 9.2775 | fde: 15.5758 | aiou: 0.7468 | fiou: 0.6227\n",
      "e: 38  | train_loss: 0.9536  | val_loss: 1.6547 | ade: 9.2720 | fde: 15.5619 | aiou: 0.7488 | fiou: 0.6272\n",
      "e: 39  | train_loss: 0.9505  | val_loss: 1.6603 | ade: 9.2435 | fde: 15.4799 | aiou: 0.7480 | fiou: 0.6263\n",
      "e: 40  | train_loss: 0.9462  | val_loss: 1.6754 | ade: 9.3167 | fde: 15.5522 | aiou: 0.7483 | fiou: 0.6267\n",
      "e: 41  | train_loss: 0.9425  | val_loss: 1.6898 | ade: 9.2977 | fde: 15.6460 | aiou: 0.7479 | fiou: 0.6240\n",
      "e: 42  | train_loss: 0.9380  | val_loss: 1.6552 | ade: 9.1743 | fde: 15.3018 | aiou: 0.7493 | fiou: 0.6285\n",
      "e: 43  | train_loss: 0.9343  | val_loss: 1.6806 | ade: 9.3278 | fde: 15.6281 | aiou: 0.7486 | fiou: 0.6276\n",
      "e: 44  | train_loss: 0.9300  | val_loss: 1.6649 | ade: 9.2264 | fde: 15.4272 | aiou: 0.7485 | fiou: 0.6265\n",
      "e: 45  | train_loss: 0.9268  | val_loss: 1.6871 | ade: 9.3679 | fde: 15.7282 | aiou: 0.7464 | fiou: 0.6237\n",
      "e: 46  | train_loss: 0.9220  | val_loss: 1.6596 | ade: 9.2190 | fde: 15.4255 | aiou: 0.7494 | fiou: 0.6291\n",
      "e: 47  | train_loss: 0.9183  | val_loss: 1.6862 | ade: 9.3290 | fde: 15.6601 | aiou: 0.7474 | fiou: 0.6254\n",
      "e: 48  | train_loss: 0.9144  | val_loss: 1.6901 | ade: 9.2035 | fde: 15.2902 | aiou: 0.7485 | fiou: 0.6285\n",
      "e: 49  | train_loss: 0.9109  | val_loss: 1.6893 | ade: 9.3052 | fde: 15.6076 | aiou: 0.7482 | fiou: 0.6256\n",
      "e: 50  | train_loss: 0.9068  | val_loss: 1.6908 | ade: 9.2088 | fde: 15.3633 | aiou: 0.7504 | fiou: 0.6300\n",
      "e: 51  | train_loss: 0.9035  | val_loss: 1.7047 | ade: 9.3121 | fde: 15.6346 | aiou: 0.7462 | fiou: 0.6213\n",
      "e: 52  | train_loss: 0.9000  | val_loss: 1.7036 | ade: 9.2328 | fde: 15.4428 | aiou: 0.7488 | fiou: 0.6282\n",
      "e: 53  | train_loss: 0.8951  | val_loss: 1.6993 | ade: 9.2346 | fde: 15.5044 | aiou: 0.7497 | fiou: 0.6281\n",
      "Epoch    54: reducing learning rate of group 0 to 1.2500e-05.\n",
      "e: 54  | train_loss: 0.8919  | val_loss: 1.7068 | ade: 9.2355 | fde: 15.4595 | aiou: 0.7498 | fiou: 0.6300\n",
      "e: 55  | train_loss: 0.8815  | val_loss: 1.7104 | ade: 9.2563 | fde: 15.4797 | aiou: 0.7483 | fiou: 0.6263\n",
      "e: 56  | train_loss: 0.8784  | val_loss: 1.6887 | ade: 9.2294 | fde: 15.4161 | aiou: 0.7490 | fiou: 0.6284\n",
      "e: 57  | train_loss: 0.8762  | val_loss: 1.6943 | ade: 9.2150 | fde: 15.4291 | aiou: 0.7495 | fiou: 0.6282\n",
      "e: 58  | train_loss: 0.8746  | val_loss: 1.7002 | ade: 9.2399 | fde: 15.4630 | aiou: 0.7488 | fiou: 0.6264\n",
      "e: 59  | train_loss: 0.8725  | val_loss: 1.7092 | ade: 9.2461 | fde: 15.4662 | aiou: 0.7486 | fiou: 0.6269\n",
      "e: 60  | train_loss: 0.8700  | val_loss: 1.7103 | ade: 9.2609 | fde: 15.5283 | aiou: 0.7489 | fiou: 0.6263\n",
      "e: 61  | train_loss: 0.8682  | val_loss: 1.6985 | ade: 9.2119 | fde: 15.4031 | aiou: 0.7493 | fiou: 0.6286\n",
      "e: 62  | train_loss: 0.8662  | val_loss: 1.7245 | ade: 9.2554 | fde: 15.4965 | aiou: 0.7491 | fiou: 0.6282\n",
      "e: 63  | train_loss: 0.8641  | val_loss: 1.7214 | ade: 9.3131 | fde: 15.6257 | aiou: 0.7478 | fiou: 0.6247\n",
      "e: 64  | train_loss: 0.8622  | val_loss: 1.7168 | ade: 9.2917 | fde: 15.5854 | aiou: 0.7484 | fiou: 0.6261\n",
      "Epoch    65: reducing learning rate of group 0 to 6.2500e-06.\n",
      "e: 65  | train_loss: 0.8607  | val_loss: 1.7146 | ade: 9.2488 | fde: 15.4726 | aiou: 0.7491 | fiou: 0.6280\n",
      "e: 66  | train_loss: 0.8543  | val_loss: 1.7175 | ade: 9.2549 | fde: 15.5061 | aiou: 0.7490 | fiou: 0.6270\n",
      "e: 67  | train_loss: 0.8532  | val_loss: 1.7188 | ade: 9.2721 | fde: 15.5340 | aiou: 0.7489 | fiou: 0.6273\n",
      "e: 68  | train_loss: 0.8521  | val_loss: 1.7263 | ade: 9.3146 | fde: 15.6473 | aiou: 0.7479 | fiou: 0.6251\n",
      "e: 69  | train_loss: 0.8508  | val_loss: 1.7278 | ade: 9.3073 | fde: 15.6152 | aiou: 0.7480 | fiou: 0.6254\n",
      "e: 70  | train_loss: 0.8503  | val_loss: 1.7166 | ade: 9.2740 | fde: 15.5495 | aiou: 0.7490 | fiou: 0.6271\n",
      "e: 71  | train_loss: 0.8491  | val_loss: 1.7147 | ade: 9.2701 | fde: 15.5108 | aiou: 0.7483 | fiou: 0.6260\n",
      "e: 72  | train_loss: 0.8481  | val_loss: 1.7212 | ade: 9.2652 | fde: 15.4857 | aiou: 0.7487 | fiou: 0.6266\n",
      "e: 73  | train_loss: 0.8472  | val_loss: 1.7155 | ade: 9.2995 | fde: 15.6111 | aiou: 0.7482 | fiou: 0.6256\n",
      "e: 74  | train_loss: 0.8460  | val_loss: 1.7193 | ade: 9.2912 | fde: 15.6153 | aiou: 0.7479 | fiou: 0.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 75  | train_loss: 0.8453  | val_loss: 1.7211 | ade: 9.2833 | fde: 15.5488 | aiou: 0.7481 | fiou: 0.6260\n",
      "Epoch    76: reducing learning rate of group 0 to 3.1250e-06.\n",
      "e: 76  | train_loss: 0.8441  | val_loss: 1.7239 | ade: 9.2358 | fde: 15.4913 | aiou: 0.7487 | fiou: 0.6259\n",
      "e: 77  | train_loss: 0.8411  | val_loss: 1.7183 | ade: 9.2989 | fde: 15.6106 | aiou: 0.7483 | fiou: 0.6261\n",
      "e: 78  | train_loss: 0.8405  | val_loss: 1.7288 | ade: 9.2952 | fde: 15.5928 | aiou: 0.7480 | fiou: 0.6255\n",
      "e: 79  | train_loss: 0.8400  | val_loss: 1.7260 | ade: 9.2886 | fde: 15.5733 | aiou: 0.7483 | fiou: 0.6262\n",
      "e: 80  | train_loss: 0.8394  | val_loss: 1.7272 | ade: 9.2877 | fde: 15.5847 | aiou: 0.7484 | fiou: 0.6257\n",
      "e: 81  | train_loss: 0.8390  | val_loss: 1.7278 | ade: 9.3035 | fde: 15.6014 | aiou: 0.7479 | fiou: 0.6254\n",
      "e: 82  | train_loss: 0.8385  | val_loss: 1.7246 | ade: 9.2818 | fde: 15.5957 | aiou: 0.7484 | fiou: 0.6261\n",
      "e: 83  | train_loss: 0.8381  | val_loss: 1.7262 | ade: 9.2747 | fde: 15.5872 | aiou: 0.7487 | fiou: 0.6263\n",
      "e: 84  | train_loss: 0.8374  | val_loss: 1.7221 | ade: 9.2464 | fde: 15.5067 | aiou: 0.7490 | fiou: 0.6269\n",
      "e: 85  | train_loss: 0.8370  | val_loss: 1.7334 | ade: 9.3014 | fde: 15.6186 | aiou: 0.7482 | fiou: 0.6257\n",
      "e: 86  | train_loss: 0.8364  | val_loss: 1.7161 | ade: 9.2620 | fde: 15.5345 | aiou: 0.7487 | fiou: 0.6267\n",
      "Epoch    87: reducing learning rate of group 0 to 1.5625e-06.\n",
      "e: 87  | train_loss: 0.8359  | val_loss: 1.7311 | ade: 9.3073 | fde: 15.6376 | aiou: 0.7480 | fiou: 0.6252\n",
      "e: 88  | train_loss: 0.8343  | val_loss: 1.7159 | ade: 9.2697 | fde: 15.5577 | aiou: 0.7485 | fiou: 0.6259\n",
      "e: 89  | train_loss: 0.8341  | val_loss: 1.7080 | ade: 9.2591 | fde: 15.5463 | aiou: 0.7486 | fiou: 0.6260\n",
      "e: 90  | train_loss: 0.8338  | val_loss: 1.7317 | ade: 9.2793 | fde: 15.5730 | aiou: 0.7483 | fiou: 0.6257\n",
      "e: 91  | train_loss: 0.8336  | val_loss: 1.7303 | ade: 9.2784 | fde: 15.5870 | aiou: 0.7482 | fiou: 0.6252\n",
      "e: 92  | train_loss: 0.8333  | val_loss: 1.7305 | ade: 9.2873 | fde: 15.5808 | aiou: 0.7483 | fiou: 0.6261\n",
      "e: 93  | train_loss: 0.8330  | val_loss: 1.7203 | ade: 9.2815 | fde: 15.5772 | aiou: 0.7485 | fiou: 0.6259\n",
      "e: 94  | train_loss: 0.8327  | val_loss: 1.7235 | ade: 9.3147 | fde: 15.6519 | aiou: 0.7478 | fiou: 0.6251\n",
      "e: 95  | train_loss: 0.8326  | val_loss: 1.7309 | ade: 9.2765 | fde: 15.5795 | aiou: 0.7486 | fiou: 0.6262\n",
      "e: 96  | train_loss: 0.8322  | val_loss: 1.7297 | ade: 9.2454 | fde: 15.5192 | aiou: 0.7494 | fiou: 0.6271\n",
      "e: 97  | train_loss: 0.8321  | val_loss: 1.7298 | ade: 9.2854 | fde: 15.6086 | aiou: 0.7482 | fiou: 0.6255\n",
      "Epoch    98: reducing learning rate of group 0 to 7.8125e-07.\n",
      "e: 98  | train_loss: 0.8318  | val_loss: 1.7336 | ade: 9.3041 | fde: 15.6322 | aiou: 0.7481 | fiou: 0.6255\n",
      "e: 99  | train_loss: 0.8309  | val_loss: 1.7237 | ade: 9.2464 | fde: 15.5050 | aiou: 0.7488 | fiou: 0.6267\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    avg_epoch_train_loss = 0\n",
    "    avg_epoch_val_loss = 0\n",
    "    ade = 0\n",
    "    fde = 0\n",
    "    aiou = 0\n",
    "    fiou = 0\n",
    "    counter = 0\n",
    "    for idx, (obs, target, obs_p, target_p) in enumerate(train):\n",
    "        counter += 1\n",
    "        obs = obs.type(torch.float32).to(device='cuda')\n",
    "        target = target.type(torch.float32).to(device='cuda')\n",
    "        obs_p = obs_p.type(torch.float32).to(device='cuda')\n",
    "        target_p = target_p.type(torch.float32).to(device='cuda')\n",
    "        \n",
    "        net.zero_grad()\n",
    "        preds = net(obs_p, obs)\n",
    "        train_loss = criterion(preds, target)/10\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_epoch_train_loss += float(train_loss)\n",
    "        \n",
    "    avg_epoch_train_loss/=counter\n",
    "    train_scores.append(avg_epoch_train_loss)\n",
    "    \n",
    "    counter=0\n",
    "    for idx, (obs, target, obs_p, target_p) in enumerate(test):\n",
    "        counter+=1\n",
    "        obs = obs.type(torch.float32).to(device='cuda')\n",
    "        target = target.type(torch.float32).to(device='cuda')\n",
    "        obs_p = obs_p.type(torch.float32).to(device='cuda')\n",
    "        target_p = target_p.type(torch.float32).to(device='cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = net(obs_p, obs)\n",
    "            val_loss = criterion(preds, target)/10\n",
    "            preds_p = utils.speed2pos(preds, obs_p, 20, 'cuda')\n",
    "            ade += float(utils.ADE_c(preds_p, target_p[:,:-1,:]))\n",
    "            fde += float(utils.FDE_c(preds_p, target_p[:,:-1,:]))\n",
    "            aiou += float(utils.AIOU(preds_p, target_p[:,:-1,:]))\n",
    "            fiou += float(utils.FIOU(preds_p, target_p[:,:-1,:]))\n",
    "            \n",
    "        avg_epoch_val_loss += float(val_loss)\n",
    "        \n",
    "    avg_epoch_val_loss/=counter\n",
    "    val_scores.append(avg_epoch_val_loss)\n",
    "    ade/=counter\n",
    "    fde/=counter     \n",
    "    aiou/=counter\n",
    "    fiou/=counter\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print('e:', epoch, ' | train_loss: %.4f'% avg_epoch_train_loss, ' | val_loss: %.4f'% avg_epoch_val_loss, \n",
    "          '| ade: %.4f'% ade, '| fde: %.4f'% fde, '| aiou: %.4f'% aiou, '| fiou: %.4f'% fiou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.1737 | ade: 9.3038 | fde: 15.5964 | aiou: 0.7479 | fiou: 0.6256\n"
     ]
    }
   ],
   "source": [
    "avg_epoch_val_loss = 0\n",
    "ade = 0\n",
    "fde = 0\n",
    "aiou = 0\n",
    "fiou = 0\n",
    "counter=0\n",
    "for idx, (obs, target, obs_p, target_p) in enumerate(test):\n",
    "    counter+=1\n",
    "    obs = obs.type(torch.float32).to(device='cuda')\n",
    "    target = target.type(torch.float32).to(device='cuda')\n",
    "    obs_p = obs_p.type(torch.float32).to(device='cuda')\n",
    "    target_p = target_p.type(torch.float32).to(device='cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = net(obs_p[:,1:,:], obs)\n",
    "        val_loss = criterion(preds, target)/100\n",
    "        preds_p = utils.speed2pos(preds, obs_p.to('cuda'), 20, 'cuda')\n",
    "        ade += float(utils.ADE_c(preds_p, target_p[:,:-1,:]))\n",
    "        fde += float(utils.FDE_c(preds_p, target_p[:,:-1,:]))\n",
    "        aiou += float(utils.AIOU(preds_p, target_p[:,:-1,:]))\n",
    "        fiou += float(utils.FIOU(preds_p, target_p[:,:-1,:]))\n",
    "\n",
    "    avg_epoch_val_loss += float(val_loss)\n",
    "\n",
    "avg_epoch_val_loss/=counter\n",
    "ade/=counter\n",
    "fde/=counter     \n",
    "aiou/=counter\n",
    "fiou/=counter\n",
    "print('val_loss: %.4f'% avg_epoch_val_loss, '| ade: %.4f'% ade, '| fde: %.4f'% fde, '| aiou: %.4f'% aiou, '| fiou: %.4f'% fiou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
